{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_GoogleNews_Cleaner_Splitter_Classification_Aggregator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richlysakowski/natural-language-processing/blob/master/tutorials/04_GoogleNews_Cleaner_Splitter_Classification_Aggregator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23R6n3CjjMzV"
      },
      "source": [
        "# Obsei Tutorial 04\n",
        "## This example shows following Obsei workflow\n",
        " 1. Observe: Search and fetch news article via Google News\n",
        " 2. Cleaner: Clean article text proerply\n",
        " 3. Analyze: Classify article text while splitting text in small chunks and later computing final inference using given formula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQiAxuEqlMpB"
      },
      "source": [
        "## Install Obsei from latest code, perform these steps -\n",
        "- Select GPU RunType for faster computation\n",
        "- Restart Runtime after installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CSwBGl1xis5q",
        "outputId": "00d1b3a3-6197-4b29-9643-2c34e1175f31"
      },
      "source": [
        "!pip install obsei[all]\n",
        "!pip install trafilatura"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting obsei[all]\n",
            "  Downloading obsei-0.0.15-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (4.12.3)\n",
            "Collecting dateparser>=1.2.0 (from obsei[all])\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting mmh3>=4.0.1 (from obsei[all])\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting pydantic-settings>=2.1.0 (from obsei[all])\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2023.3.post1 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2024.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.32.3)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.24 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.0.36)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9.3->obsei[all]) (2.6)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.2.0->obsei[all]) (2024.9.11)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.2.0->obsei[all]) (5.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->obsei[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->obsei[all]) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.3->obsei[all]) (4.12.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.1.0->obsei[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->obsei[all]) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->obsei[all]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->obsei[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->obsei[all]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->obsei[all]) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.24->obsei[all]) (3.1.1)\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (3.9.1)\n",
            "Collecting presidio-analyzer>=2.2.351 (from obsei[all])\n",
            "  Downloading presidio_analyzer-2.2.355-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting presidio-anonymizer>=2.2.351 (from obsei[all])\n",
            "  Downloading presidio_anonymizer-2.2.355-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (0.2.0)\n",
            "Requirement already satisfied: spacy>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (3.7.5)\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.36.2 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (4.46.2)\n",
            "Collecting vadersentiment>=3.3.2 (from obsei[all])\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->obsei[all]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->obsei[all]) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->obsei[all]) (4.66.6)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer>=2.2.351->obsei[all])\n",
            "  Downloading phonenumbers-8.13.50-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer>=2.2.351->obsei[all]) (6.0.2)\n",
            "Collecting tldextract (from presidio-analyzer>=2.2.351->obsei[all])\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core (from presidio-anonymizer>=2.2.351->obsei[all])\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio-anonymizer>=2.2.351->obsei[all])\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (0.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.7.2->obsei[all]) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->obsei[all]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->obsei[all]) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->obsei[all]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->obsei[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.2->obsei[all]) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.2->obsei[all]) (0.26.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.2->obsei[all]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.2->obsei[all]) (0.20.3)\n",
            "Collecting searchtweets-v2>=1.1.1 (from obsei[all])\n",
            "  Downloading searchtweets_v2-1.1.1-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting app-store-reviews-reader>=1.2 (from obsei[all])\n",
            "  Downloading app_store_reviews_reader-1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-play-scraper>=1.2.4 (from obsei[all])\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=2.111.0 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.151.0)\n",
            "Collecting elasticsearch>=8.11.1 (from obsei[all])\n",
            "  Downloading elasticsearch-8.16.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting atlassian-python-api>=3.41.4 (from obsei[all])\n",
            "  Downloading atlassian_python_api-3.41.16-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from obsei[all]) (2.2.2)\n",
            "Collecting slack-sdk>=3.26.1 (from obsei[all])\n",
            "  Downloading slack_sdk-3.33.4-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Collecting python-facebook-api>=0.15.0 (from obsei[all])\n",
            "  Downloading python_facebook_api-0.20.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting reddit-rss-reader>=1.3.2 (from obsei[all])\n",
            "  Downloading reddit_rss_reader-1.3.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting googlenews>=1.6.12 (from obsei[all])\n",
            "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting praw>=7.7.1 (from obsei[all])\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting feedparser (from app-store-reviews-reader>=1.2->obsei[all])\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api>=3.41.4->obsei[all]) (1.2.15)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api>=3.41.4->obsei[all]) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from atlassian-python-api>=3.41.4->obsei[all]) (1.3.1)\n",
            "Collecting jmespath (from atlassian-python-api>=3.41.4->obsei[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch>=8.11.1->obsei[all])\n",
            "  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.111.0->obsei[all]) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.111.0->obsei[all]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.111.0->obsei[all]) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.111.0->obsei[all]) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.111.0->obsei[all]) (4.1.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->obsei[all]) (1.2.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->obsei[all]) (2024.2)\n",
            "Collecting prawcore<3,>=2.4 (from praw>=7.7.1->obsei[all])\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw>=7.7.1->obsei[all])\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw>=7.7.1->obsei[all]) (1.8.0)\n",
            "Collecting dataclasses-json>=0.5.7 (from python-facebook-api>=0.15.0->obsei[all])\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.7.2->obsei[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.7.2->obsei[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->obsei[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.7.2->obsei[all]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->obsei[all]) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.7.2->obsei[all]) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.7.2->obsei[all]) (3.0.2)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer>=2.2.351->obsei[all])\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.5.7->python-facebook-api>=0.15.0->obsei[all])\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.5.7->python-facebook-api>=0.15.0->obsei[all])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=2.111.0->obsei[all]) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=2.111.0->obsei[all]) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=2.111.0->obsei[all]) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.111.0->obsei[all]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.111.0->obsei[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.111.0->obsei[all]) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.111.0->obsei[all]) (3.2.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.7.2->obsei[all]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->obsei[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->obsei[all]) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.7.2->obsei[all]) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser->app-store-reviews-reader>=1.2->obsei[all])\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.7.2->obsei[all]) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.111.0->obsei[all]) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.5.7->python-facebook-api>=0.15.0->obsei[all])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading obsei-0.0.15-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_analyzer-2.2.355-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.2/109.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.355-py3-none-any.whl (31 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading app_store_reviews_reader-1.2-py3-none-any.whl (8.4 kB)\n",
            "Downloading atlassian_python_api-3.41.16-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.9/177.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elasticsearch-8.16.0-py3-none-any.whl (543 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.1/543.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
            "Downloading phonenumbers-8.13.50-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_facebook_api-0.20.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading reddit_rss_reader-1.3.2-py3-none-any.whl (8.5 kB)\n",
            "Downloading searchtweets_v2-1.1.1-py3-none-any.whl (32 kB)\n",
            "Downloading slack_sdk-3.33.4-py2.py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=58ffe11c84d9707f55cd1babde170ec0b8c8a3a7fe37e0429c7107a7b2dc378c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, phonenumbers, slack-sdk, python-dotenv, pycryptodome, mypy-extensions, mmh3, marshmallow, jmespath, google-play-scraper, feedparser, elastic-transport, vadersentiment, update_checker, typing-inspect, searchtweets-v2, requests-file, reddit-rss-reader, prawcore, elasticsearch, dateparser, azure-core, app-store-reviews-reader, tldextract, pydantic-settings, presidio-anonymizer, praw, googlenews, dataclasses-json, atlassian-python-api, python-facebook-api, obsei, presidio-analyzer\n",
            "Successfully installed app-store-reviews-reader-1.2 atlassian-python-api-3.41.16 azure-core-1.32.0 dataclasses-json-0.6.7 dateparser-1.2.0 elastic-transport-8.15.1 elasticsearch-8.16.0 feedparser-6.0.11 google-play-scraper-1.2.7 googlenews-1.6.15 jmespath-1.0.1 marshmallow-3.23.1 mmh3-5.0.1 mypy-extensions-1.0.0 obsei-0.0.15 phonenumbers-8.13.50 praw-7.8.1 prawcore-2.4.0 presidio-analyzer-2.2.355 presidio-anonymizer-2.2.355 pycryptodome-3.21.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 python-facebook-api-0.20.1 reddit-rss-reader-1.3.2 requests-file-2.1.0 searchtweets-v2-1.1.1 sgmllib3k-1.0.0 slack-sdk-3.33.4 tldextract-5.1.3 typing-inspect-0.9.0 update_checker-0.18.0 vadersentiment-3.3.2\n",
            "Collecting trafilatura\n",
            "  Downloading trafilatura-1.12.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2024.8.30)\n",
            "Collecting courlan>=1.2.0 (from trafilatura)\n",
            "  Downloading courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.8.1 (from trafilatura)\n",
            "  Downloading htmldate-1.9.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura)\n",
            "  Downloading jusText-3.0.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: lxml>=5.2.2 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from trafilatura) (2.2.3)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=1.2.0->trafilatura) (2.16.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.2.0->trafilatura)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: dateparser>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.8.1->trafilatura) (1.2.0)\n",
            "Collecting python-dateutil>=2.9.0.post0 (from htmldate>=1.8.1->trafilatura)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (2024.9.11)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura) (5.2)\n",
            "Collecting lxml-html-clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
            "  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.8.1->trafilatura) (1.16.0)\n",
            "Downloading trafilatura-1.12.2-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.2/132.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
            "Downloading htmldate-1.9.2-py3-none-any.whl (31 kB)\n",
            "Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tld, python-dateutil, lxml-html-clean, courlan, justext, htmldate, trafilatura\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "Successfully installed courlan-1.3.2 htmldate-1.9.2 justext-3.0.1 lxml-html-clean-0.4.1 python-dateutil-2.9.0.post0 tld-0.13 trafilatura-1.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              },
              "id": "a5b39854abc7435b9a8928ea9216c02a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "G6IQmCanfOBt",
        "outputId": "169f909e-4e93-4d6b-d545-d2453fa3df9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEIG7Zs-lQVB"
      },
      "source": [
        "## Configure Google News Observer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASPOB5Alla7q"
      },
      "source": [
        "from obsei.source.google_news_source import GoogleNewsConfig, GoogleNewsSource\n",
        "\n",
        "source_config = GoogleNewsConfig(\n",
        "    query=\"bitcoin\",\n",
        "    max_results=10,\n",
        "    fetch_article=True,\n",
        "    lookup_period=\"1d\",\n",
        ")\n",
        "\n",
        "source = GoogleNewsSource()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJJ06rpalsYB"
      },
      "source": [
        "## Configure TextCleaner as Pre-Processor to clean review text\n",
        "These cleaning function will run serially"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TksY24crlsy6",
        "outputId": "171fa1ad-1d6a-4671-ff46-ee3f7956ec36"
      },
      "source": [
        "from obsei.preprocessor.text_cleaner import TextCleaner, TextCleanerConfig\n",
        "from obsei.preprocessor.text_cleaning_function import *\n",
        "\n",
        "text_cleaner_config = TextCleanerConfig(\n",
        "    cleaning_functions = [\n",
        "        ToLowerCase(),\n",
        "        RemoveWhiteSpaceAndEmptyToken(),\n",
        "        RemovePunctuation(),\n",
        "        RemoveSpecialChars(),\n",
        "        DecodeUnicode(),\n",
        "        RemoveStopWords(),\n",
        "        RemoveWhiteSpaceAndEmptyToken(),\n",
        "   ]\n",
        ")\n",
        "\n",
        "text_cleaner = TextCleaner()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z45pE_BVl_gu"
      },
      "source": [
        "## Configure Classification Analyzer\n",
        "\n",
        "- List of categories in `labels`\n",
        "- `TextSplitterConfig` with proper `max_split_length` and `split_stride`\n",
        "- `InferenceAggregatorConfig` with required `aggregate_function` currently two are supported (average and max frequent class)\n",
        "- `ClassificationMaxCategories` need `score_threshold` which is used to determine what minimum probability needed to take a class into consideration\n",
        "\n",
        "**Note**: Select model from https://huggingface.co/models?pipeline_tag=zero-shot-classification, if you want to try different one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGzOD5yrl_CB"
      },
      "source": [
        "from obsei.analyzer.classification_analyzer import ClassificationAnalyzerConfig, ZeroShotClassificationAnalyzer\n",
        "from obsei.postprocessor.inference_aggregator import InferenceAggregatorConfig\n",
        "from obsei.postprocessor.inference_aggregator_function import ClassificationMaxCategories\n",
        "from obsei.preprocessor.text_splitter import TextSplitterConfig\n",
        "\n",
        "analyzer_config=ClassificationAnalyzerConfig(\n",
        "   labels=[\"buy\", \"sell\", \"going up\", \"going down\"],\n",
        "   use_splitter_and_aggregator=True,\n",
        "   splitter_config=TextSplitterConfig(\n",
        "       max_split_length=300,\n",
        "       split_stride=3\n",
        "   ),\n",
        "   aggregator_config=InferenceAggregatorConfig(\n",
        "       aggregate_function=ClassificationMaxCategories(\n",
        "           score_threshold=0.3\n",
        "       )\n",
        "   )\n",
        ")\n",
        "\n",
        "text_analyzer = ZeroShotClassificationAnalyzer(\n",
        "   model_name_or_path=\"typeform/mobilebert-uncased-mnli\",\n",
        "   device=\"auto\"\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScovHM79oMLo"
      },
      "source": [
        "## Search and fetch news article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WniWcEzeoOKx",
        "outputId": "4a3b691f-425e-489b-e663-f2f379f9d741"
      },
      "source": [
        "source_response_list = source.lookup(source_config)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'<' not supported between instances of 'float' and 'datetime.datetime'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEvZ32HZoY57"
      },
      "source": [
        "## PreProcess text to clean it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpFEbn1joYbK"
      },
      "source": [
        "cleaner_response_list = text_cleaner.preprocess_input(\n",
        "    input_list=source_response_list,\n",
        "    config=text_cleaner_config\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ztptWCECfJ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsh3e3uCogxK"
      },
      "source": [
        "## Analyze article to perform classification\n",
        "**Note**: This is compute heavy step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSe3F6EyohX9",
        "outputId": "da3dc228-8501-41cb-c554-f6cadd62df63"
      },
      "source": [
        "analyzer_response_list = text_analyzer.analyze_input(\n",
        "    source_response_list=cleaner_response_list,\n",
        "    analyzer_config=analyzer_config\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS9Oc4DrovN_"
      },
      "source": [
        "## Print Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl7OIaDxov3L",
        "outputId": "50df2a30-d9c4-407f-85ed-e8d1d5ed807d"
      },
      "source": [
        "for analyzer_response in analyzer_response_list:\n",
        "  print(vars(analyzer_response))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'segmented_data': {'aggregator_data': {'category_count': {'going up': 1, 'positive': 1, 'negative': 1}, 'max_scores': {'going up': 0.8165131211280823, 'positive': 0.6288111209869385, 'negative': 0.42871829867362976}, 'aggregator_name': 'ClassificationMaxCategories'}}, 'meta': {'title': 'Bitcoin nears $100,000 as investors bet on crypto-friendly Trump policies', 'desc': None, 'date': '3 hours ago', 'datetime': datetime.datetime(2024, 11, 22, 3, 10, 4, 175132), 'link': 'https://news.google.com/read/CBMitwFBVV95cUxOMFMwQjh2RDV5eUxTSVJKNFJxQ2Y3YVI0N05YNXA0VUF1X25wUXd2aWpLQUVzcGtsQXkyZlJQaWVnLVNnX0xUOGQyeE1uM3NXeFVSd1FHQk54TGJvQ1VTMDZkQ1FOY3hmZ0pTVDFGdXl0eGZHcWRBd2lwUTdfMURZNmZOdnRiY3VlcXQ3cmV2MU1idzUyNWxKbVhOMUdzY19vOUVrMFhCbDBHdHQ3R2J3Nk8wQktaajjSAbwBQVVfeXFMUEJhNURDUVhlcnRNazZOSk1nQ0JPRk5HOERCdnVmRjF3b1lwWTA0WXhwNkM1ZTl4SXdIYUVsTWtfeEdJb0RtSVpzS2VmaG14VG5kNzMzc2lxRG1GcjVsRVdXTFRQWTNKOWl5RFNWRVg1X0xQLXptWGhyNWpwbXdyaVEySHItSHZjbFpiNzJqSnJEN0JPR0hGd1NwY0VyZEIwVmNzeGh1QklTTFpzQVpyMmpYSjBNaU9ENndqNVM?hl=en-US&gl=US&ceid=US%3Aen', 'img': 'https://news.google.com/api/attachments/CC8iK0NnNVpPRGxsT0dGWVJUUnZRamRsVFJEQ0FSaURBaWdCTWdhSllJeUdNZ1k=-w200-h112-p-df', 'media': 'Al Jazeera English', 'site': None, 'reporter': None, 'extracted_data': {}}, 'source_name': 'GoogleNews', 'processed_text': 'bitcoin nears 100000 investors bet cryptofriendly trump policies'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tn3lBcBofsga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Add Python code to retrieve the full text of the article above and put it in the cell below.\n",
        "\n",
        "# Assuming the necessary libraries and configurations are already defined as in the provided code.\n",
        "#  Specifically, source_response_list should contain the fetched articles.\n",
        "\n",
        "for response in source_response_list:\n",
        "    response.text\n",
        ""
      ],
      "metadata": {
        "id": "kgTK1S1Cft94",
        "outputId": "44862204-5504-4502-f6bc-85dc06f95bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TextPayload' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-997c1d9ab353>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_response_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TextPayload' object has no attribute 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm-BjEGEgOo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}